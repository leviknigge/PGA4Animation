{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'h5py.h5.H5PYConfig' has no attribute '__reduce_cython__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0838e82da8f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetwork_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m   \u001b[1;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m   \u001b[0mHDF5_OBJECT_HEADER_LIMIT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64512\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_version_tuple\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_built_version_tuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\version.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh5\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_h5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\h5.pyx\u001b[0m in \u001b[0;36minit h5py.h5\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'h5py.h5.H5PYConfig' has no attribute '__reduce_cython__'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as v1\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "\n",
    "# import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "def build_path(path):\n",
    "    for i in path:\n",
    "        if not os.path.exists(i):\n",
    "            os.makedirs(i)\n",
    "    \n",
    "\n",
    "def Normalize(X, axis, savefile= None):\n",
    "    Xmean, Xstd = X.mean(axis=axis), X.std(axis=axis)\n",
    "    for i in range(Xstd.size):\n",
    "        if (Xstd[i]==0):\n",
    "            Xstd[i]=1\n",
    "    X = (X - Xmean) / Xstd\n",
    "    if savefile != None:\n",
    "        Xmean.tofile(savefile+'mean.bin')\n",
    "        Xstd.tofile(savefile+'std.bin')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.248028\n",
       "1         0.247512\n",
       "2         0.247585\n",
       "3         0.247253\n",
       "4         0.247683\n",
       "            ...   \n",
       "246201   -0.119152\n",
       "246202   -0.114068\n",
       "246203   -0.108449\n",
       "246204   -0.100855\n",
       "246205   -0.094479\n",
       "Name: 0, Length: 246206, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('output.txt', header=None)\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('algebra_input.txt', delimiter=',')\n",
    "Y = np.loadtxt('algebra_output.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmean, Xstd = X.mean(axis=0), X.std(axis=0)\n",
    "Ymean, Ystd = Y.mean(axis=0), Y.std(axis=0)\n",
    "\n",
    "for i in range(Xstd.size):\n",
    "    if (Xstd[i]==0):\n",
    "        Xstd[i]=1\n",
    "for i in range(Ystd.size):\n",
    "    if (Ystd[i]==0):\n",
    "        Ystd[i]=1\n",
    "        \n",
    "X = (X - Xmean) / Xstd\n",
    "Y = (Y - Ymean) / Ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdim  = X.shape[1]\n",
    "Ydim = Y.shape[1]\n",
    "samples = X.shape[0]\n",
    "# print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nn = tf.placeholder(tf.float32, [None, Xdim], name='x-input')\n",
    "Y_nn = tf.placeholder(tf.float32, [None, Ydim], name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 186)\n",
      "(?, 186)\n"
     ]
    }
   ],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "H0 = X_nn[:,:-1] \n",
    "# H0 = tf.expand_dims(H0, -1)       \n",
    "H0 = tf.nn.dropout(H0, keep_prob=keep_prob)\n",
    "\n",
    "b0 = bias_variable([512])\n",
    "W0 = weight_variable([Xdim-1,512])\n",
    "\n",
    "# print(b0.shape)\n",
    "# print(W0.shape)\n",
    "# print(H0.shape)\n",
    "\n",
    "H1 = tf.matmul(H0, W0) + b0\n",
    "# print(H1.shape, \"lol\")\n",
    "H1 = tf.nn.elu(H1)\n",
    "H1 = tf.nn.dropout(H1, keep_prob=keep_prob)\n",
    "\n",
    "layer = tf.keras.layers.LayerNormalization(axis=1, epsilon=0.0000001)\n",
    "H1 = layer(H1)\n",
    "\n",
    "b1 = bias_variable([512])\n",
    "W1 = weight_variable([512,512])\n",
    "\n",
    "# print(b1.shape)\n",
    "# print(W1.shape)\n",
    "# print(H1.shape)\n",
    "\n",
    "H2 = tf.matmul(H1, W1) + b1\n",
    "H2 = tf.nn.elu(H2)\n",
    "H2 = tf.nn.dropout(H1, keep_prob=keep_prob)\n",
    "\n",
    "layer = tf.keras.layers.LayerNormalization(axis=1, epsilon=0.0000001)\n",
    "H2 = layer(H2)\n",
    "\n",
    "b2 = bias_variable([Ydim])\n",
    "W2 = weight_variable([512,Ydim])\n",
    "\n",
    "H3 = tf.matmul(H2, W2) + b2\n",
    "# H3 = tf.squeeze(H3, -1)\n",
    "\n",
    "print(Y_nn.shape)\n",
    "print(H3.shape)\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.square(Y_nn - H3), reduction_indices=[1])\n",
    "\n",
    "loss_shit = tf.reduce_mean(tf.square(Y_nn - H3))\n",
    "\n",
    "def loss():\n",
    "    return tf.reduce_mean(tf.square(Y_nn - H3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate      = 0.001\n",
    "weightDecay        = 0.001\n",
    "\n",
    "clr = learning_rate\n",
    "wdc = weightDecay\n",
    "# , wdc = [0.0005,0.01]\n",
    "\n",
    "\n",
    "batch_size         = 32\n",
    "training_epochs    = 150\n",
    "Te                 = 16\n",
    "Tmult              = 2\n",
    "total_batch        = int(samples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(\n",
    "    learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False,\n",
    "    name='Adam'\n",
    ").minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_step = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.025, beta_2=0.25).minimize(loss, var_list=[b0,W0,b1,W1,b2,W2])\n",
    "\n",
    "lr_c = tf.placeholder(tf.float32)\n",
    "wd_c = tf.placeholder(tf.float32)\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.0025).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(H3, 1), tf.argmax(Y_nn, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# initialize the graph\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_batch: 403\n"
     ]
    }
   ],
   "source": [
    "print(\"total_batch:\", total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_batch: 323\n",
      "test_batch: 80\n"
     ]
    }
   ],
   "source": [
    "I = np.arange(samples)\n",
    "\n",
    "count_test     = .2\n",
    "num_testBatch  = np.int(total_batch * count_test)\n",
    "num_trainBatch = total_batch - num_testBatch\n",
    "print(\"training_batch:\", num_trainBatch)\n",
    "print(\"test_batch:\", num_testBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train = np.ones((training_epochs,batch_size))\n",
    "error_test  = np.ones((training_epochs,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# tf.set_random_seed(23456)  # reproducibility\n",
    "\n",
    "class AdamWParameter:\n",
    "    def __init__(self, nEpochs = 150, Te=10, Tmult=2, LR=0.0001, weightDecay=0.0025, batchSize=32, nBatches = 0):\n",
    "        self.nEpochs     = nEpochs                #number of total epoch\n",
    "        self.Te          = Te                     #Ti: total number of epochs within the i-th run / restart of the algorithm\n",
    "        self.Tmult       = Tmult                  \n",
    "        self.LR          = LR                     #learning rate\n",
    "        self.weightDecay = weightDecay            #learning rate decay rate \n",
    "        self.batchSize   = batchSize              #bt: batch size                   \n",
    "        self.nBatches    = nBatches               #number of total batch\n",
    "        self.EpochNext   = self.Te + 1            #next restart epoch\n",
    "        self.T_cur       = 0   \n",
    "        self.t           = 0 \n",
    "        self.wd          = self.weightDecayNormalized()\n",
    "        self.H_cur       = 0.9\n",
    "    \n",
    "    \n",
    "    #yita\n",
    "    def learningRateCosineSGDR(self, epoch):\n",
    "        self.T_cur = self.T_cur + 1.0 / (self.Te * self.nBatches)\n",
    "        if self.T_cur >= self.H_cur:\n",
    "            self.T_cur = self.H_cur\n",
    "        if (self.T_cur >= self.H_cur) and (epoch == self.EpochNext):\n",
    "            self.T_cur = 0\n",
    "            self.Te = self.Te * self.Tmult\n",
    "            self.EpochNext = self.EpochNext + self.Te\n",
    "        \n",
    "        return 0.5 * (1 + np.cos(np.pi * self.T_cur))\n",
    "\n",
    "    #wt\n",
    "    def weightDecayNormalized(self):\n",
    "        return self.weightDecay / (np.power(self.nBatches * self.Te, 0.5))\n",
    "    \n",
    "    \n",
    "    #update and get paramter every epoch\n",
    "    def getParameter(self, epoch):\n",
    "        \n",
    "        yita = self.learningRateCosineSGDR(epoch)\n",
    "        lr   = yita * self.LR\n",
    "        clr  = lr/(1+self.t*0)                               #currentLearningRate\n",
    "        wdc  = yita * self.wd                                #weightDecayCurrent\n",
    "        self.t +=1 \n",
    "        return (\n",
    "                np.float32(clr),\n",
    "                np.float32(wdc)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AdamWParameter(nEpochs      = training_epochs, \n",
    "                    Te           = Te,\n",
    "                    Tmult        = Tmult,\n",
    "                    LR           = learning_rate, \n",
    "                    weightDecay  = weightDecay,\n",
    "                    batchSize    = batch_size,\n",
    "                    nBatches     = total_batch\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start..\n",
      "Epoch: 0001 trainingloss = 0.38812393\n",
      "Epoch: 0001 testloss = 0.56527454\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0002 trainingloss = 0.25476813\n",
      "Epoch: 0002 testloss = 0.48326188\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0003 trainingloss = 0.22246125\n",
      "Epoch: 0003 testloss = 0.4471696\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0004 trainingloss = 0.20571963\n",
      "Epoch: 0004 testloss = 0.4260388\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0005 trainingloss = 0.19571194\n",
      "Epoch: 0005 testloss = 0.41165453\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0006 trainingloss = 0.18836373\n",
      "Epoch: 0006 testloss = 0.40037352\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0007 trainingloss = 0.18227336\n",
      "Epoch: 0007 testloss = 0.39163586\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0008 trainingloss = 0.17831558\n",
      "Epoch: 0008 testloss = 0.38561475\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0009 trainingloss = 0.17457388\n",
      "Epoch: 0009 testloss = 0.37964934\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0010 trainingloss = 0.1712982\n",
      "Epoch: 0010 testloss = 0.37495077\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0011 trainingloss = 0.1687573\n",
      "Epoch: 0011 testloss = 0.37062868\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0012 trainingloss = 0.1662112\n",
      "Epoch: 0012 testloss = 0.36739686\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0013 trainingloss = 0.16417609\n",
      "Epoch: 0013 testloss = 0.36412472\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0014 trainingloss = 0.16271332\n",
      "Epoch: 0014 testloss = 0.36126763\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0015 trainingloss = 0.16179594\n",
      "Epoch: 0015 testloss = 0.3587282\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0016 trainingloss = 0.16025424\n",
      "Epoch: 0016 testloss = 0.35690492\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0017 trainingloss = 0.15861368\n",
      "Epoch: 0017 testloss = 0.35437572\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0018 trainingloss = 0.15788788\n",
      "Epoch: 0018 testloss = 0.3534907\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0019 trainingloss = 0.1567134\n",
      "Epoch: 0019 testloss = 0.35125703\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0020 trainingloss = 0.15593907\n",
      "Epoch: 0020 testloss = 0.34933794\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0021 trainingloss = 0.15489802\n",
      "Epoch: 0021 testloss = 0.34828353\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0022 trainingloss = 0.15467787\n",
      "Epoch: 0022 testloss = 0.34701526\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0023 trainingloss = 0.15333933\n",
      "Epoch: 0023 testloss = 0.34611148\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0024 trainingloss = 0.1527107\n",
      "Epoch: 0024 testloss = 0.3450352\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0025 trainingloss = 0.15204579\n",
      "Epoch: 0025 testloss = 0.34363335\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0026 trainingloss = 0.15132055\n",
      "Epoch: 0026 testloss = 0.34253505\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0027 trainingloss = 0.15152144\n",
      "Epoch: 0027 testloss = 0.34158424\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0028 trainingloss = 0.1506046\n",
      "Epoch: 0028 testloss = 0.34126157\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0029 trainingloss = 0.15017438\n",
      "Epoch: 0029 testloss = 0.340901\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0030 trainingloss = 0.1498254\n",
      "Epoch: 0030 testloss = 0.33970064\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0031 trainingloss = 0.14947057\n",
      "Epoch: 0031 testloss = 0.3384474\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0032 trainingloss = 0.14894623\n",
      "Epoch: 0032 testloss = 0.33782887\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0033 trainingloss = 0.14883518\n",
      "Epoch: 0033 testloss = 0.33774126\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0034 trainingloss = 0.14881727\n",
      "Epoch: 0034 testloss = 0.33658215\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0035 trainingloss = 0.14813907\n",
      "Epoch: 0035 testloss = 0.33608302\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0036 trainingloss = 0.14808914\n",
      "Epoch: 0036 testloss = 0.33577174\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0037 trainingloss = 0.14739718\n",
      "Epoch: 0037 testloss = 0.33512884\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0038 trainingloss = 0.14676858\n",
      "Epoch: 0038 testloss = 0.33469957\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0039 trainingloss = 0.14726749\n",
      "Epoch: 0039 testloss = 0.3342032\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0040 trainingloss = 0.14622691\n",
      "Epoch: 0040 testloss = 0.33381817\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0041 trainingloss = 0.14650637\n",
      "Epoch: 0041 testloss = 0.33364087\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0042 trainingloss = 0.14675468\n",
      "Epoch: 0042 testloss = 0.33292717\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0043 trainingloss = 0.14575745\n",
      "Epoch: 0043 testloss = 0.3325371\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0044 trainingloss = 0.14567322\n",
      "Epoch: 0044 testloss = 0.33285853\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0045 trainingloss = 0.14564642\n",
      "Epoch: 0045 testloss = 0.33196652\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0046 trainingloss = 0.14506644\n",
      "Epoch: 0046 testloss = 0.33161592\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0047 trainingloss = 0.14450578\n",
      "Epoch: 0047 testloss = 0.33086422\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0048 trainingloss = 0.14488122\n",
      "Epoch: 0048 testloss = 0.3313105\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0049 trainingloss = 0.1447244\n",
      "Epoch: 0049 testloss = 0.33100662\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0050 trainingloss = 0.14442715\n",
      "Epoch: 0050 testloss = 0.3308462\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0051 trainingloss = 0.14467293\n",
      "Epoch: 0051 testloss = 0.33040386\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0052 trainingloss = 0.14378974\n",
      "Epoch: 0052 testloss = 0.33019698\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0053 trainingloss = 0.14453776\n",
      "Epoch: 0053 testloss = 0.329841\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0054 trainingloss = 0.1442069\n",
      "Epoch: 0054 testloss = 0.32901633\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0055 trainingloss = 0.14325294\n",
      "Epoch: 0055 testloss = 0.32978237\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0056 trainingloss = 0.14307785\n",
      "Epoch: 0056 testloss = 0.32912976\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0057 trainingloss = 0.14338225\n",
      "Epoch: 0057 testloss = 0.32851362\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0058 trainingloss = 0.14325824\n",
      "Epoch: 0058 testloss = 0.32844573\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0059 trainingloss = 0.14320356\n",
      "Epoch: 0059 testloss = 0.32839748\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0060 trainingloss = 0.14272846\n",
      "Epoch: 0060 testloss = 0.32820123\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0061 trainingloss = 0.14270173\n",
      "Epoch: 0061 testloss = 0.327955\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0062 trainingloss = 0.14313234\n",
      "Epoch: 0062 testloss = 0.32792795\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0063 trainingloss = 0.14195177\n",
      "Epoch: 0063 testloss = 0.32707474\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0064 trainingloss = 0.14232764\n",
      "Epoch: 0064 testloss = 0.32757717\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0065 trainingloss = 0.14195734\n",
      "Epoch: 0065 testloss = 0.32748434\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0066 trainingloss = 0.14200193\n",
      "Epoch: 0066 testloss = 0.32715017\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0067 trainingloss = 0.14136398\n",
      "Epoch: 0067 testloss = 0.32758135\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0068 trainingloss = 0.14154762\n",
      "Epoch: 0068 testloss = 0.3269347\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0069 trainingloss = 0.14173068\n",
      "Epoch: 0069 testloss = 0.3270055\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0070 trainingloss = 0.14158383\n",
      "Epoch: 0070 testloss = 0.32655433\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0071 trainingloss = 0.14197871\n",
      "Epoch: 0071 testloss = 0.3264475\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0072 trainingloss = 0.14135548\n",
      "Epoch: 0072 testloss = 0.3265772\n",
      "model saved in: training/model/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0073 trainingloss = 0.14132488\n",
      "Epoch: 0073 testloss = 0.3264734\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0074 trainingloss = 0.14100136\n",
      "Epoch: 0074 testloss = 0.3260042\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0075 trainingloss = 0.1413863\n",
      "Epoch: 0075 testloss = 0.32591027\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0076 trainingloss = 0.14117041\n",
      "Epoch: 0076 testloss = 0.32594112\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0077 trainingloss = 0.14088191\n",
      "Epoch: 0077 testloss = 0.32652605\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0078 trainingloss = 0.1404904\n",
      "Epoch: 0078 testloss = 0.32579553\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0079 trainingloss = 0.14106312\n",
      "Epoch: 0079 testloss = 0.32607615\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0080 trainingloss = 0.14065796\n",
      "Epoch: 0080 testloss = 0.32594365\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0081 trainingloss = 0.14029187\n",
      "Epoch: 0081 testloss = 0.32604712\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0082 trainingloss = 0.14043349\n",
      "Epoch: 0082 testloss = 0.3258056\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0083 trainingloss = 0.14036787\n",
      "Epoch: 0083 testloss = 0.32639086\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0084 trainingloss = 0.14032857\n",
      "Epoch: 0084 testloss = 0.32625777\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0085 trainingloss = 0.14045489\n",
      "Epoch: 0085 testloss = 0.3261537\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0086 trainingloss = 0.1403188\n",
      "Epoch: 0086 testloss = 0.32654655\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0087 trainingloss = 0.1400055\n",
      "Epoch: 0087 testloss = 0.32585132\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0088 trainingloss = 0.1395334\n",
      "Epoch: 0088 testloss = 0.32581088\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0089 trainingloss = 0.13974866\n",
      "Epoch: 0089 testloss = 0.32558483\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0090 trainingloss = 0.13986635\n",
      "Epoch: 0090 testloss = 0.3251899\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0091 trainingloss = 0.13981089\n",
      "Epoch: 0091 testloss = 0.3249124\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0092 trainingloss = 0.13916829\n",
      "Epoch: 0092 testloss = 0.32538533\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0093 trainingloss = 0.13975343\n",
      "Epoch: 0093 testloss = 0.32490385\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0094 trainingloss = 0.13949469\n",
      "Epoch: 0094 testloss = 0.32625508\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0095 trainingloss = 0.13988832\n",
      "Epoch: 0095 testloss = 0.32573086\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0096 trainingloss = 0.13909718\n",
      "Epoch: 0096 testloss = 0.32513762\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0097 trainingloss = 0.13898665\n",
      "Epoch: 0097 testloss = 0.32510728\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0098 trainingloss = 0.1390718\n",
      "Epoch: 0098 testloss = 0.32540917\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0099 trainingloss = 0.13916813\n",
      "Epoch: 0099 testloss = 0.32527092\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0100 trainingloss = 0.13951257\n",
      "Epoch: 0100 testloss = 0.3264839\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0101 trainingloss = 0.13887288\n",
      "Epoch: 0101 testloss = 0.32525414\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0102 trainingloss = 0.13871597\n",
      "Epoch: 0102 testloss = 0.32547802\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0103 trainingloss = 0.13880548\n",
      "Epoch: 0103 testloss = 0.3252098\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0104 trainingloss = 0.13915327\n",
      "Epoch: 0104 testloss = 0.32539588\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0105 trainingloss = 0.13924554\n",
      "Epoch: 0105 testloss = 0.32474244\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0106 trainingloss = 0.13895264\n",
      "Epoch: 0106 testloss = 0.32538536\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0107 trainingloss = 0.13922901\n",
      "Epoch: 0107 testloss = 0.3252926\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0108 trainingloss = 0.13857096\n",
      "Epoch: 0108 testloss = 0.3249517\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0109 trainingloss = 0.13852276\n",
      "Epoch: 0109 testloss = 0.3249342\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0110 trainingloss = 0.1383071\n",
      "Epoch: 0110 testloss = 0.32570982\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0111 trainingloss = 0.13840261\n",
      "Epoch: 0111 testloss = 0.325204\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0112 trainingloss = 0.13823411\n",
      "Epoch: 0112 testloss = 0.3249104\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0113 trainingloss = 0.13848758\n",
      "Epoch: 0113 testloss = 0.32473803\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0114 trainingloss = 0.13833636\n",
      "Epoch: 0114 testloss = 0.32531\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0115 trainingloss = 0.13746361\n",
      "Epoch: 0115 testloss = 0.32569218\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0116 trainingloss = 0.13783008\n",
      "Epoch: 0116 testloss = 0.32493615\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0117 trainingloss = 0.13796389\n",
      "Epoch: 0117 testloss = 0.32583016\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0118 trainingloss = 0.13775092\n",
      "Epoch: 0118 testloss = 0.32499462\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0119 trainingloss = 0.13760357\n",
      "Epoch: 0119 testloss = 0.32540876\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0120 trainingloss = 0.13790041\n",
      "Epoch: 0120 testloss = 0.3251931\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0121 trainingloss = 0.13808808\n",
      "Epoch: 0121 testloss = 0.3256268\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0122 trainingloss = 0.13667658\n",
      "Epoch: 0122 testloss = 0.3258911\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0123 trainingloss = 0.13707201\n",
      "Epoch: 0123 testloss = 0.32572466\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0124 trainingloss = 0.13733049\n",
      "Epoch: 0124 testloss = 0.32579735\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0125 trainingloss = 0.1376606\n",
      "Epoch: 0125 testloss = 0.3260601\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0126 trainingloss = 0.13796383\n",
      "Epoch: 0126 testloss = 0.3256025\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0127 trainingloss = 0.13728793\n",
      "Epoch: 0127 testloss = 0.3257241\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0128 trainingloss = 0.13733649\n",
      "Epoch: 0128 testloss = 0.3255754\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0129 trainingloss = 0.13724944\n",
      "Epoch: 0129 testloss = 0.3258599\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0130 trainingloss = 0.13607007\n",
      "Epoch: 0130 testloss = 0.3257106\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0131 trainingloss = 0.13687634\n",
      "Epoch: 0131 testloss = 0.32596374\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0132 trainingloss = 0.13697118\n",
      "Epoch: 0132 testloss = 0.32566395\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0133 trainingloss = 0.1365077\n",
      "Epoch: 0133 testloss = 0.3259029\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0134 trainingloss = 0.13631527\n",
      "Epoch: 0134 testloss = 0.32580686\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0135 trainingloss = 0.13797137\n",
      "Epoch: 0135 testloss = 0.326018\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0136 trainingloss = 0.13659354\n",
      "Epoch: 0136 testloss = 0.3260926\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0137 trainingloss = 0.13712664\n",
      "Epoch: 0137 testloss = 0.32571334\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0138 trainingloss = 0.13699223\n",
      "Epoch: 0138 testloss = 0.32568866\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0139 trainingloss = 0.13725549\n",
      "Epoch: 0139 testloss = 0.32594\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0140 trainingloss = 0.13639323\n",
      "Epoch: 0140 testloss = 0.32614776\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0141 trainingloss = 0.13662046\n",
      "Epoch: 0141 testloss = 0.32587516\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0142 trainingloss = 0.13619936\n",
      "Epoch: 0142 testloss = 0.32594243\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0143 trainingloss = 0.13587134\n",
      "Epoch: 0143 testloss = 0.32641962\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0144 trainingloss = 0.13646826\n",
      "Epoch: 0144 testloss = 0.32681835\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0145 trainingloss = 0.13617434\n",
      "Epoch: 0145 testloss = 0.326909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0146 trainingloss = 0.13626654\n",
      "Epoch: 0146 testloss = 0.32706943\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0147 trainingloss = 0.1372379\n",
      "Epoch: 0147 testloss = 0.32729584\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0148 trainingloss = 0.1356182\n",
      "Epoch: 0148 testloss = 0.3272813\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0149 trainingloss = 0.13680899\n",
      "Epoch: 0149 testloss = 0.3271486\n",
      "model saved in: training/model/model.ckpt\n",
      "Epoch: 0150 trainingloss = 0.13647923\n",
      "Epoch: 0150 testloss = 0.3267081\n",
      "model saved in: training/model/model.ckpt\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "print('Learning start..')\n",
    "\n",
    "TESTNUMBER = 2\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_train = 0\n",
    "    avg_cost_test  = 0\n",
    "    \n",
    "    for i in range(num_trainBatch):\n",
    "        index_train = I[i*batch_size:(i+1)*batch_size]\n",
    "        batch_xs = X[index_train]\n",
    "        batch_ys = Y[index_train]\n",
    "#         clr, wdc = ap.getParameter(epoch)   #currentLearningRate & weightDecayCurrent\n",
    "#         clr,wdc = ap.getParameter(epoch)\n",
    "    \n",
    "        feed_dict = {X_nn: batch_xs, Y_nn: batch_ys, keep_prob: 0.7, lr_c: clr, wd_c: wdc}\n",
    "        l, _, = sess.run([cross_entropy, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost_train += l / num_trainBatch\n",
    "\n",
    "    \n",
    "    for i in range(num_testBatch):\n",
    "        if i==0:\n",
    "            index_test = I[-(i+1)*batch_size: ]\n",
    "        else:\n",
    "            index_test = I[-(i+1)*batch_size: -i*batch_size]\n",
    "        batch_xs = X[index_test]\n",
    "        batch_ys = Y[index_test]\n",
    "        feed_dict = {X_nn: batch_xs, Y_nn: batch_ys, keep_prob: 1}\n",
    "        testError = sess.run(cross_entropy, feed_dict=feed_dict)\n",
    "        avg_cost_test += testError / num_testBatch       \n",
    "#         if i % 1000 == 0:\n",
    "#             print(i, \"testloss:\",testError)\n",
    "            \n",
    "            \n",
    "    print('Epoch:',  '%04d' % (epoch + 1), 'trainingloss =', np.mean(avg_cost_train))\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'testloss =', np.mean(avg_cost_test))\n",
    "    \n",
    "    with open(\"training/epochrates\"+str(TESTNUMBER)+\".txt\", \"a\") as f:\n",
    "        f.write('Epoch: ' +  '%04d' % (epoch + 1) + ' trainingloss = '+ str(np.mean(avg_cost_train))+\"\\n\")\n",
    "        f.write('Epoch: ' +  '%04d' % (epoch + 1) + ' testloss = '+ str(np.mean(avg_cost_test))+\"\\n\\n\")\n",
    "    \n",
    "    error_train[epoch] = avg_cost_train\n",
    "    error_test[epoch]  = avg_cost_test\n",
    "    \n",
    "    error_train.tofile(\"training/model/error_train.bin\")\n",
    "    error_test.tofile(\"training/model/error_test.bin\")\n",
    "\n",
    "    save_path = saver.save(sess, \"training/model/model.ckpt\")\n",
    "    print(\"model saved in:\", \"training/model/model.ckpt\")\n",
    "                     \n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Epoch:', '0150', 'trainingloss =', 0.13136181)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Epoch:',  '%04d' % (epoch + 1), 'trainingloss =', np.mean(avg_cost_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_path(['data'])\n",
    "build_path(['training'])\n",
    "build_path(['training/nn'])\n",
    "build_path(['training/weights'])\n",
    "build_path(['training/model'])\n",
    "build_path(['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = X[:658]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {X_nn : testing, keep_prob : 1}\n",
    "lol = sess.run(H3, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(658, 186)\n"
     ]
    }
   ],
   "source": [
    "print(lol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_01_01 = np.around(lol * Ystd + Ymean, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_01_01 = np.around(Y[:658] * Ystd + Ymean, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_01_01 = np.loadtxt('output.txt', delimiter=',')[:658]\n",
    "output_01_01 = np.loadtxt(\"output_Algebra_01_01.txt\", delimiter=\",\")[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(658, 186)\n",
      "(658, 186)\n"
     ]
    }
   ],
   "source": [
    "print(output_01_01.shape)\n",
    "print(Y_01_01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.248028  0.52702  -0.568856  0.046869 -0.021253 -0.038151] [ 0.196861  0.527795 -0.409708  0.031153 -0.082547 -0.03182 ]\n"
     ]
    }
   ],
   "source": [
    "output_01_01 == lol_01_01\n",
    "\n",
    "print(output_01_01[0,:6], lol_01_01[0,:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.248028  0.52702  -0.568856  0.046869 -0.021253 -0.038151]\n",
      "[ 0.248028  0.52702  -0.568856  0.046869 -0.021253 -0.038151]\n"
     ]
    }
   ],
   "source": [
    "print(Y_01_01[0,:6])\n",
    "print(output_01_01[0,:6])\n",
    "\n",
    "# for i in range(Y_01_01.shape[0]):\n",
    "#     if sum(Y[i] == output_01_01[50]) > 46:\n",
    "#         print(sum(Y_01_01[i] == output_01_01[30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cur = np.array([X[0]])\n",
    "shit = np.zeros(output_01_01.shape)\n",
    "\n",
    "for i in range(output_01_01.shape[0]):\n",
    "    \n",
    "    gen_cur = np.array([X[i]])\n",
    "    \n",
    "    if i > 0:\n",
    "        gen_cur[0,:186] = gen_nex\n",
    "    \n",
    "    feed_dict = {X_nn : gen_cur, keep_prob : 1}\n",
    "    \n",
    "    gen_nex = sess.run(H3, feed_dict=feed_dict)\n",
    "    shit[i] = gen_nex\n",
    "\n",
    "\n",
    "shit_01_01 = np.around(shit * Ystd + Ymean, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1930.1921010000008\n",
      "4807.504580999998\n"
     ]
    }
   ],
   "source": [
    "print(sum(sum(abs(output_01_01 - lol_01_01))))\n",
    "print(sum(sum(abs(output_01_01 - shit_01_01))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/test.txt\", \"w+\") as f:\n",
    "    for row in lol_01_01:\n",
    "        f.write(\",\".join(format(x, \"1.6f\") for x in row) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/gen_test.txt\", \"w+\") as f:\n",
    "    for row in shit_01_01:\n",
    "        f.write(\",\".join(format(x, \"1.6f\") for x in row) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir():\n",
    "    if \"output_Algebra_01\" in filename:\n",
    "        print(filename)\n",
    "        data = pd.read_csv(filename, header = None)\n",
    "        output = data[30:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
